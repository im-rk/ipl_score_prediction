# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c3ZTnUD23ZPy5p_7vB6Wk7YBDXF0KUU8

#DATA PREPROCESSING

##Import libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

"""##Loading the dataset"""

dataset=pd.read_csv('ipl_data.csv')
dataset.head()

"""##Dropping the unnecessary features"""

df=dataset.drop(['date','runs','wickets','overs','runs_last_5','wickets_last_5','mid','striker','non-striker'],axis=1)

print(df)

"""##Taking care of missing data"""

print(df.isnull().sum())
df.drop(67414,axis=0)

"""##Splitting dependent and independent variable"""

X=df.drop(['total'],axis=1)
y=df['total']

print(X)

print(y)

"""##Encoding the data"""

from sklearn.preprocessing import LabelEncoder
venue_encoder = LabelEncoder()
batting_team_encoder = LabelEncoder()
bowling_team_encoder = LabelEncoder()
striker_encoder = LabelEncoder()
bowler_encoder = LabelEncoder()
X['venue'] = venue_encoder.fit_transform(X['venue'])
X['bat_team'] = batting_team_encoder.fit_transform(X['bat_team'])
X['bowl_team'] = bowling_team_encoder.fit_transform(X['bowl_team'])
X['batsman'] = striker_encoder.fit_transform(X['batsman'])
X['bowler'] = bowler_encoder.fit_transform(X['bowler'])

"""##Splitting the dataset into training set and test set"""

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)

print(X_train)

print(X_test)

print(y_train)

print(y_test)

"""##Feature Scaling"""

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""#Definig Model"""

import keras
import tensorflow as tf

# Define the neural network model
model = keras.Sequential([
    keras.layers.Input( shape=(X_train.shape[1],)),
    keras.layers.Dense(512, activation='relu'),
    keras.layers.Dense(216, activation='relu'),
    keras.layers.Dense(1, activation='linear')
])

huber_loss = tf.keras.losses.Huber(delta=1.0)
model.compile(optimizer='adam', loss=huber_loss)

"""#Training Model"""

# Train the model
model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test))

y_pred=model.predict(X_test)
from sklearn.metrics import mean_absolute_error,mean_squared_error
mean_absolute_error(y_test,y_pred)